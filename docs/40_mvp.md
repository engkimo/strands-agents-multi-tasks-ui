# MVP 計画

## スコープ（必須）
- ツール 2〜4 種の登録（Claude Code / Codex CLI / Gemini CLI / Spec Kit）。
- 同一入力の並列実行（Best-of-N）と結果比較（差分ビュー）。
- 実行グラフ/ノード詳細（I/O/ログ/時間/エラー）可視化。
- 実行履歴保存とワンクリック再実行（seed/環境の記録）。
- 提供形態: ローカル Web UI。

## 非対象（MVP 外）
- 複雑なアクセス制御/監査ログ、多人数同時編集。
- 本格的なモデル評価/自動ルーティング（骨格のみ用意）。
- マルチテナント運用/大規模クラウド配備。

## タイムライン（例: 4 週間・1 名）
- W1: ツールラッパー/実行基盤/保存層の骨格、単発実行。
- W2: 並列実行(Graph/Swarm)と基本 UI、ログ/トレース表示。
- W3: 履歴/再実行/差分、安定化、エラー/リトライ。
- W4: 仕上げ（UX/パフォーマンス）、簡易評価ハーネス、デモ準備。

## 受け入れ基準
- 指定ツールを同一入力で並列実行し、結果比較が UI で可能。
- 実行途中の状態遷移とノード I/O/ログが可視化される。
- 履歴から再実行し、結果の差分が確認できる。

## デモシナリオ（例）
1. プロンプトとツールセット選択 → 実行。
2. グラフで並列ノードが動作、各ノードの I/O/ログを表示。
3. 完了後、差分ビューで各出力を比較 → ベストを採用。
4. 履歴から再実行し、差分が再現されることを確認。

## リスクと軽減策
- CLI 互換性/安定性: タイムアウト/再試行/標準出力の正規化。
- 外部 API レート制限: キャッシュ/キュー/指数バックオフ。
- モデル品質のばらつき: Best-of-N/評価ハーネスで緩和。

参照: `../01_requirements.md`
