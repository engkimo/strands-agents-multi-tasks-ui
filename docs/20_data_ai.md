# データ設計 / AI 方針

## 収集対象（メタデータ）
- 実行単位（Run）: 実行 ID、開始/終了、ステータス、トリガー情報、ユーザー。
- ノード（Node）: ツール名、入力、出力、標準出力/標準エラー、実行時間、リトライ回数。
- コスト/トークン: モデル別の消費量と推定コスト。
- トレース/イベント: OTel の Span/属性、例外、リンク。
- 環境: ツール/モデルのバージョン、OS、依存関係ハッシュ。

## スキーマ（MVP 例）
- `runs(id, created_at, status, trigger, user)`
- `nodes(id, run_id, name, type, started_at, ended_at, status, retry, error)`
- `artifacts(id, node_id, kind, mime, path_or_blob)`
- `metrics(id, owner_id, owner_kind, key, value, unit)`
- `traces(span_id, parent_id, node_id, attrs_json)`

（実装は SQLite/ファイルストレージ + JSON フィールドで開始し、将来外部 DB へ移行）

## プライバシー/コンプライアンス
- MVP 方針: ミニマム（完全ローカル必須ではない）。
- PII/機密情報は入力段階でマスキング可能に（ルール/辞書/正規表現）。
- ログ/アーティファクトの保持期間ポリシー（期間は要決定。MVP は短期）。
- 外部送信の明示と制御（モデル推論/テレメトリ）。

## AI/オーケストレーション方針
- ルーティング: ルールベース（タスク種別→推奨ツール）から開始、将来は評価スコア/コスト/レイテンシで動的最適化。
- 並列化: Best-of-N（同時実行→選抜）と Hedge（早い/良い方を採用）をタスクで選択可能に。
- 失敗時復帰: ノード単位でリトライ/フォールバックツールを設定。
- キャッシュ: 入力→出力の内容ハッシュでメモ化（TTL/バージョン付け）。

## 評価（将来機能の土台）
- データセット: タスク ID、入力、期待条件（例: テスト通過、語数、カバレッジ）。
- 自動判定: コードならビルド/テスト、テキストならルーブリック採点（モデル採点はバイアス検証付き）。
- オフライン再現: 固定 Seed/環境固定での再実行、スコア比較。

## セキュリティ
- 実行サンドボックス: ファイル/ネットワーク権限の最小化、危険コマンド制限。
- 入力バリデーション: シェル/引数インジェクション対策、拡張子/パス検証。

参照: `../01_requirements.md`
